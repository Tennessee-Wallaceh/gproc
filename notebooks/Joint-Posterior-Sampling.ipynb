{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "515c47ec-d7d3-4d90-9582-43aa16e33716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from gproc.elliptic import ess_samples_probit\n",
    "from gproc.metropolis_hastings import mh, mh_step\n",
    "from gproc.generative import sample_at_x\n",
    "from gproc.kernels import *\n",
    "from gproc.laplace import laplace_approximation_probit, chol_inverse\n",
    "from gproc.approx_marginal_is import importance_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6508f1d-467c-4879-a890-42322873fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500 # Data size\n",
    "D = 1 # Data dimension\n",
    "\n",
    "x = np.random.normal(0, 1, N * D).reshape(-1, D) # Reshape to N x D matrix\n",
    "y, prob_y, f = sample_at_x(x, kernel_fcn = squared_exponential, kernel_params = {'lengthscale': 1, 'variance': 3})\n",
    "\n",
    "th_0 = np.array([1, 1])\n",
    "gram = squared_exponential(x, x, lengthscale = th_0[0], variance = th_0[1])\n",
    "inverse_gram = chol_inverse(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3a68767-6955-42eb-87d3-00ddac9e474c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-241.30652310192406"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get approximation to latent function posterior\n",
    "laplace_mean, df_ll, laplace_cov, objective_history, converged = laplace_approximation_probit(y, inverse_gram)\n",
    "\n",
    "print(f'Converged: {converged}')\n",
    "\n",
    "marg_0 = importance_sampler(y, x, laplace_mean, laplace_cov, 100)\n",
    "marg_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68cf9ec6-ccc6-487d-99d5-229b494b66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_sampler(iters, y, x, th_0, marg_0, cov, N_imp = 100, burn_in = 10, verbose = True):\n",
    "    \"\"\"\n",
    "    Function that jointly samples from the posterior distribution over\n",
    "    kernel parameters and the latent functions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    iters: float\n",
    "        number of iterations of the Metropolis Hastings algorithm\n",
    "        \n",
    "    y: N dimensional numpy vector\n",
    "        responses\n",
    "    \n",
    "    x: N x D dimensional numpy array\n",
    "        covariates\n",
    "\n",
    "    th_0: numpy vector\n",
    "        initial kernel parameters\n",
    "\n",
    "    marg_0: float\n",
    "        initial approximation of the marginal\n",
    "        \n",
    "    cov: numpy array\n",
    "        covariance matrix for use in the proposal distribution\n",
    "        \n",
    "    N_imp: float\n",
    "        number of importance samples to use in marginal approximation\n",
    "    \n",
    "    burn_in: float\n",
    "        number of burn in samples to use in ELL-SS\n",
    "        \n",
    "    verbose: boolean\n",
    "        flag to produce loading bar\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    f_arr: numpy array\n",
    "        contains the latent function samples\n",
    "        \n",
    "    th_arr: numpy array\n",
    "        contains the kernel parmams chains move history\n",
    "    \n",
    "    marg_arr: numpy array\n",
    "        contains the history of marginal approximations\n",
    "    \n",
    "    acc_rate: float\n",
    "        acceptance rate of moves\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create array to hold samples and move history\n",
    "    f_arr = np.zeros((iters, y.shape[0]))\n",
    "    th_arr = np.zeros((iters + 1, th_0.shape[0]))\n",
    "    marg_arr = np.zeros(iters + 1)\n",
    "    move_arr = np.zeros(iters)\n",
    "    \n",
    "    # Add initialisation\n",
    "    th_arr[0, :] = th_0\n",
    "    marg_arr[0] = marg_0\n",
    "    \n",
    "    for i in tqdm(range(iters), disable=not(verbose)):\n",
    "        # Get latent function sample corresponding to current kernel params\n",
    "        K = squared_exponential(x, x, lengthscale = th_arr[i, 0], variance = th_arr[i, 1])\n",
    "        K_chol = np.linalg.cholesky(gram + 1e-05 * np.eye(K.shape[0]))\n",
    "        f_arr[i, :] = ess_samples_probit(K_chol, y, 1, burn_in, verbose = False)\n",
    "        \n",
    "        # Get new kernel params\n",
    "        th_arr[i + 1, :], marg_arr[i + 1], move_arr[i] = mh_step(y, x, th_arr[i, :], marg_arr[i], cov = cov, N_imp = N_imp)\n",
    "    \n",
    "    acc_rate = move_arr.mean()\n",
    "    return f_arr, th_arr, marg_arr, acc_rate\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc717eee-eb15-4af2-ab47-562eec60f3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35ddbc6b5d149e0aaab5b6d1453adbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.08362084, -0.19135684, -0.85827698, ..., -0.0615982 ,\n",
       "         -0.71063466,  0.19186821],\n",
       "        [-0.20574987, -0.19740925, -0.50278077, ..., -0.03712025,\n",
       "         -0.58628714,  0.15373615],\n",
       "        [-0.49838621, -0.04802172, -0.75994161, ...,  0.04697815,\n",
       "         -0.32563357, -0.01320167],\n",
       "        ...,\n",
       "        [-0.19673967, -0.01132922, -0.40740815, ...,  0.05679463,\n",
       "         -0.7536686 ,  0.08948268],\n",
       "        [-0.08741976, -0.38496345, -0.24680834, ..., -0.18480007,\n",
       "         -0.53088378,  0.24797968],\n",
       "        [-0.11612013,  0.07906859, -0.68583613, ...,  0.15740341,\n",
       "         -0.68587266,  0.19921962]]),\n",
       " array([[ 1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ],\n",
       "        [ 1.        ,  1.        ],\n",
       "        [-0.40361126,  1.0479887 ],\n",
       "        [-0.40361126,  1.0479887 ],\n",
       "        [-0.40361126,  1.0479887 ],\n",
       "        [-0.40361126,  1.0479887 ],\n",
       "        [-0.40361126,  1.0479887 ],\n",
       "        [-0.56620034,  0.31653308],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.53902405,  0.76614246],\n",
       "        [-0.50174378,  0.35764584],\n",
       "        [-0.50174378,  0.35764584],\n",
       "        [-0.50174378,  0.35764584],\n",
       "        [-0.50174378,  0.35764584],\n",
       "        [-0.50174378,  0.35764584],\n",
       "        [-0.50174378,  0.35764584],\n",
       "        [-0.50174378,  0.35764584],\n",
       "        [-0.50174378,  0.35764584],\n",
       "        [-0.50174378,  0.35764584],\n",
       "        [-0.50174378,  0.35764584],\n",
       "        [-0.50174378,  0.35764584],\n",
       "        [-0.50174378,  0.35764584],\n",
       "        [-0.50174378,  0.35764584],\n",
       "        [-0.60703695,  0.51776775],\n",
       "        [-0.60703695,  0.51776775],\n",
       "        [-0.60703695,  0.51776775],\n",
       "        [-0.60703695,  0.51776775],\n",
       "        [-0.60703695,  0.51776775],\n",
       "        [-0.60703695,  0.51776775],\n",
       "        [-0.60703695,  0.51776775],\n",
       "        [-0.60703695,  0.51776775],\n",
       "        [-0.60703695,  0.51776775],\n",
       "        [-0.60703695,  0.51776775],\n",
       "        [-0.69541997,  0.05275915],\n",
       "        [-0.69541997,  0.05275915],\n",
       "        [-0.69541997,  0.05275915],\n",
       "        [-0.69541997,  0.05275915],\n",
       "        [-0.69541997,  0.05275915],\n",
       "        [-0.69541997,  0.05275915],\n",
       "        [-0.69541997,  0.05275915],\n",
       "        [-0.69541997,  0.05275915],\n",
       "        [-0.69541997,  0.05275915],\n",
       "        [-0.69541997,  0.05275915],\n",
       "        [-0.69541997,  0.05275915]]),\n",
       " array([-241.3065231 , -241.3065231 , -241.3065231 , -241.3065231 ,\n",
       "        -241.3065231 , -241.3065231 , -241.3065231 , -241.3065231 ,\n",
       "        -241.3065231 , -241.3065231 , -241.3065231 , -241.3065231 ,\n",
       "        -241.3065231 , -241.3065231 , -241.3065231 , -241.3065231 ,\n",
       "        -221.8177226 , -221.8177226 , -221.8177226 , -221.8177226 ,\n",
       "        -221.8177226 , -223.00113834, -222.80486298, -222.80486298,\n",
       "        -222.80486298, -222.80486298, -222.80486298, -222.80486298,\n",
       "        -222.80486298, -222.80486298, -222.80486298, -222.80486298,\n",
       "        -222.80486298, -222.80486298, -222.80486298, -222.80486298,\n",
       "        -222.80486298, -222.80486298, -222.80486298, -222.80486298,\n",
       "        -222.80486298, -222.80486298, -222.80486298, -222.80486298,\n",
       "        -222.80486298, -222.80486298, -222.80486298, -222.80486298,\n",
       "        -222.80486298, -222.80486298, -222.80486298, -222.80486298,\n",
       "        -222.80486298, -222.80486298, -222.80486298, -222.80486298,\n",
       "        -222.80486298, -222.80486298, -222.80486298, -222.80486298,\n",
       "        -222.80486298, -222.80486298, -222.80486298, -222.80486298,\n",
       "        -222.80486298, -222.80486298, -222.80486298, -221.43548375,\n",
       "        -221.43548375, -221.43548375, -221.43548375, -221.43548375,\n",
       "        -221.43548375, -221.43548375, -221.43548375, -221.43548375,\n",
       "        -221.43548375, -221.43548375, -221.43548375, -221.43548375,\n",
       "        -220.67320666, -220.67320666, -220.67320666, -220.67320666,\n",
       "        -220.67320666, -220.67320666, -220.67320666, -220.67320666,\n",
       "        -220.67320666, -220.67320666, -220.38391189, -220.38391189,\n",
       "        -220.38391189, -220.38391189, -220.38391189, -220.38391189,\n",
       "        -220.38391189, -220.38391189, -220.38391189, -220.38391189,\n",
       "        -220.38391189]),\n",
       " 0.06)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_sampler(100, y, x, th_0, marg_0, cov = np.eye(th_0.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a54ba9-a043-420d-9880-bfb018b6ef64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
