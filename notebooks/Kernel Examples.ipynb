{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0d15887e-f6a6-4b29-a792-4821b1aabb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import gamma, norm\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from gproc.generative import sample_at_x\n",
    "from gproc.laplace import chol_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e375d042-ae58-4ffd-b534-b3066883d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sizes and dimension\n",
    "D = 2\n",
    "N = 50\n",
    "M = 50\n",
    "\n",
    "x_1 = np.random.uniform(-1, 1, N * D).reshape(-1, D) # Reshape to N x D matrix\n",
    "x_2 = np.random.uniform(-1, 1, M * D).reshape(-1, D) # Reshape to N x D matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e3edb36d-f626-4f26-813a-022f02d1350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseKernel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def make_gram(self, x_1, x_2):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def invert_gram(self):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def constrain_params(self, unconstrained_param_array):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def prior_log_pdf(self, param_array):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3c258896-acc1-43a0-b1e1-3e8698f7a2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def squared_exponential(x_1, x_2, lengthscale=0.5, variance=1.0):\n",
    "    \"\"\"\n",
    "    Also known as RBF.\n",
    "    \n",
    "    :param x_1, N x d matrix\n",
    "    :param x_2, M x d matrix\n",
    "\n",
    "    :param lengthscale, float\n",
    "    :param variance, float\n",
    "\n",
    "    :returns K, N x M matrix, K_{ij} = k(x_i, x_j; lengthscale, variance)\n",
    "    \"\"\"\n",
    "    sq_diffs = cdist(x_1, x_2, metric = 'sqeuclidean')\n",
    "    return variance * np.exp(-0.5 * sq_diffs / lengthscale)\n",
    "\n",
    "squared_exponential(x_1, x_2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b86cfdb8-03ad-449e-9cdf-578b1541ba63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.71828183, 2.28506574, 2.70784883, ..., 2.14915104, 2.46156486,\n",
       "        2.37930197],\n",
       "       [2.28506574, 2.71828183, 2.2912546 , ..., 2.56572821, 1.83153792,\n",
       "        1.93586545],\n",
       "       [2.70784883, 2.2912546 , 2.71828183, ..., 2.21977572, 2.36397548,\n",
       "        2.47684215],\n",
       "       ...,\n",
       "       [2.14915104, 2.56572821, 2.21977572, ..., 2.71828183, 1.50466813,\n",
       "        2.16685022],\n",
       "       [2.46156486, 1.83153792, 2.36397548, ..., 1.50466813, 2.71828183,\n",
       "        1.78019102],\n",
       "       [2.37930197, 1.93586545, 2.47684215, ..., 2.16685022, 1.78019102,\n",
       "        2.71828183]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SquaredExponential(BaseKernel):\n",
    "    def __init__(self, lengthscale=0.5, variance=1.0):\n",
    "        self.lengthscale = lengthscale\n",
    "        self.variance = variance\n",
    "        self.param_dim = 2\n",
    "        super().__init__()\n",
    "    \n",
    "    def make_gram(self, x_1, x_2):\n",
    "        self.gram = squared_exponential(x_1, x_2, self.lengthscale, self.variance)\n",
    "        return self.gram \n",
    "    \n",
    "    def invert_gram(self):\n",
    "        self.inverse_gram = chol_inverse(self.gram)\n",
    "        return self.inverse_gram\n",
    "    \n",
    "    def constrain_params(self, unconstrained_params):\n",
    "        if unconstrained_params.shape[0] != self.param_dim:\n",
    "            raise AssertionError('Parameter array not the same size as kernel parameter dimension')\n",
    "        self.constrained_params = np.exp(unconstrained_params)\n",
    "        return self.constrained_params\n",
    "    \n",
    "    def update_params(self):\n",
    "        self.lengthscale = self.constrained_params[0]\n",
    "        self.variance = self.constrained_params[1]\n",
    "    \n",
    "    def prior_log_pdf(self, d):\n",
    "        self.prior = gamma.logpdf(self.constrained_params[0], a = 1, scale = np.sqrt(d))\n",
    "        self.prior += gamma.logpdf(self.constrained_params[1], a = 1.2, scale = 1/0.2)\n",
    "        return self.prior\n",
    "\n",
    "kernel = SquaredExponential(lengthscale = 1, variance = 1)\n",
    "kernel.make_gram(x_1, x_1)\n",
    "kernel.constrain_params(np.ones(2))\n",
    "kernel.update_params()\n",
    "kernel.make_gram(x_1, x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ecc5a3eb-2f49-4bac-8e1d-e3fc02a7415c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rational_quadratic(x_1, x_2, lengthscale=0.5, variance=1.0, weighting=1.0):\n",
    "    \"\"\"\n",
    "    Rational Quadratic Kernel, equivalent to adding together many Squared Exponential kernels with different \n",
    "    lengthscales. Weight parameter determine relative weighting of large and small scale variations. When\n",
    "    the weighting goes to infinity, RQ = SE.\n",
    "    \n",
    "    :param x_1, N x d matrix\n",
    "    :param x_2, M x d matrix\n",
    "\n",
    "    :param lengthscale, float\n",
    "    :param variance, float\n",
    "    :param weighting, float\n",
    "\n",
    "    :returns K, N x M matrix, K_{ij} = k(x_i, x_j; lengthscale, variance, weighting)\n",
    "    \"\"\"\n",
    "    sq_diffs = cdist(x_1, x_2, metric = 'sqeuclidean')\n",
    "    return variance * ( (1 + sq_diffs / 2*lengthscale * weighting) ** (-weighting) )\n",
    "\n",
    "rational_quadratic(x_1, x_2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "06a9c607-6c5e-4598-88f9-cac68aa8531c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14.558996227068079"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RationalQuadratic(BaseKernel):\n",
    "    def __init__(self, lengthscale=0.5, variance=1.0, weighting=1.0):\n",
    "        self.lengthscale = lengthscale\n",
    "        self.variance = variance\n",
    "        self.weighting = weighting\n",
    "        self.param_dim = 3\n",
    "        super().__init__()\n",
    "    \n",
    "    def make_gram(self, x_1, x_2):\n",
    "        self.gram = rational_quadratic(x_1, x_2, self.lengthscale, self.variance, self.weighting)\n",
    "        return self.gram \n",
    "    \n",
    "    def invert_gram(self):\n",
    "        self.inverse_gram = chol_inverse(self.gram)\n",
    "        return self.inverse_gram\n",
    "    \n",
    "    def constrain_params(self, unconstrained_params):\n",
    "        if unconstrained_params.shape[0] != self.param_dim:\n",
    "            raise AssertionError('Parameter array not the same size as kernel parameter dimension')\n",
    "        self.constrained_params = np.exp(unconstrained_params)\n",
    "        return self.constrained_params\n",
    "    \n",
    "    def update_params(self):\n",
    "        self.lengthscale = self.constrained_params[0]\n",
    "        self.variance = self.constrained_params[1]\n",
    "        self.weighting = self.constrained_params[2]\n",
    "    \n",
    "    def prior_log_pdf(self, d):\n",
    "        self.prior = gamma.logpdf(self.constrained_params[0], a = 1, scale = np.sqrt(d))\n",
    "        self.prior += gamma.logpdf(self.constrained_params[1], a = 1.2, scale = 1/0.2)\n",
    "        self.prior += gamma.logpdf(self.constrained_params[2], a = 0.00001, scale = 1/0.00001) # uninformative prior\n",
    "        return self.prior\n",
    "\n",
    "kernel = RationalQuadratic(lengthscale = 1, variance = 1, weighting = 1)\n",
    "kernel.make_gram(x_1, x_1)\n",
    "kernel.constrain_params(np.zeros(3))\n",
    "kernel.prior_log_pdf(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cfcac19d-85b4-4ee7-8938-8851b3218bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def periodic(x_1, x_2, lengthscale=0.5, variance=1.0, period=1.0):\n",
    "    \"\"\"\n",
    "    The periodic kernel allows one to model functions which repeat themselves exactly.\n",
    "    \n",
    "    :param x_1, N x d matrix\n",
    "    :param x_2, M x d matrix\n",
    "\n",
    "    :param lengthscale, float\n",
    "    :param variance, float\n",
    "    :param period, float\n",
    "\n",
    "    :returns K, N x M matrix, K_{ij} = k(x_i, x_j; lengthscale, variance, period)\n",
    "    \"\"\"\n",
    "    diffs = cdist(x_1, x_2, metric = 'euclidean')\n",
    "    return variance * np.exp(-2 * np.sin(np.pi * diffs / period)**2 / lengthscale)\n",
    "\n",
    "periodic(x_1, x_2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1fb0beec-26d6-4e66-a8ab-d86b5868fcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14.558996227068079"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Periodic(BaseKernel):\n",
    "    def __init__(self, lengthscale=0.5, variance=1.0, period=1.0):\n",
    "        self.lengthscale = lengthscale\n",
    "        self.variance = variance\n",
    "        self.period = period\n",
    "        self.param_dim = 3\n",
    "        super().__init__()\n",
    "    \n",
    "    def make_gram(self, x_1, x_2):\n",
    "        self.gram = periodic(x_1, x_2, self.lengthscale, self.variance, self.period)\n",
    "        return self.gram \n",
    "    \n",
    "    def invert_gram(self):\n",
    "        self.inverse_gram = chol_inverse(self.gram)\n",
    "        return self.inverse_gram\n",
    "    \n",
    "    def constrain_params(self, unconstrained_params):\n",
    "        if unconstrained_params.shape[0] != self.param_dim:\n",
    "            raise AssertionError('Parameter array not the same size as kernel parameter dimension')\n",
    "        self.constrained_params = np.exp(unconstrained_params)\n",
    "        return self.constrained_params\n",
    "    \n",
    "    def update_params(self):\n",
    "        self.lengthscale = self.constrained_params[0]\n",
    "        self.variance = self.constrained_params[1]\n",
    "        self.period = self.constrained_params[2]\n",
    "\n",
    "    def prior_log_pdf(self, d):\n",
    "        self.prior = gamma.logpdf(self.constrained_params[0], a = 1, scale = np.sqrt(d))\n",
    "        self.prior += gamma.logpdf(self.constrained_params[1], a = 1.2, scale = 1/0.2)\n",
    "        self.prior += gamma.logpdf(self.constrained_params[2], a = 0.00001, scale = 1/0.00001) # uninformative prior\n",
    "        return self.prior\n",
    "\n",
    "kernel = Periodic(lengthscale = 1, variance = 1, period = 10)\n",
    "kernel.make_gram(x_1, x_1)\n",
    "kernel.constrain_params(np.zeros(3))\n",
    "kernel.prior_log_pdf(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a3c04e9e-e19c-478c-adab-3b22b4ab56ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01943932, 0.29180675, 0.19719793, ..., 0.00698842, 0.03547656,\n",
       "        0.00929565],\n",
       "       [0.00697473, 0.00932752, 0.25789686, ..., 0.13097394, 0.2865392 ,\n",
       "        0.00201134],\n",
       "       [0.00894003, 0.05146021, 0.0135198 , ..., 0.03231052, 0.00431434,\n",
       "        0.01294791],\n",
       "       ...,\n",
       "       [0.0110584 , 0.01112045, 0.16290165, ..., 0.07276377, 0.09532865,\n",
       "        0.00609362],\n",
       "       [0.0233737 , 0.24850693, 0.19878202, ..., 0.00418271, 0.30323217,\n",
       "        0.01966417],\n",
       "       [0.01281723, 0.00204036, 0.00641971, ..., 0.20021683, 0.03443829,\n",
       "        0.17148864]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def locally_periodic(x_1, x_2, lengthscale_sqe=0.5, variance=1.0, lengthscale_p =0.5, period=1.0):\n",
    "    \"\"\"\n",
    "    A squared exponential kernel multiplied by a periodic kernel. Allows one to model periodic functions\n",
    "    which can vary slowly over time.\n",
    "    \n",
    "    :param x_1, N x d matrix\n",
    "    :param x_2, M x d matrix\n",
    "\n",
    "    :param lengthscale, float\n",
    "    :param variance, float\n",
    "    :param period, float\n",
    "\n",
    "    :returns K, N x M matrix, K_{ij} = k(x_i, x_j; lengthscale, variance, period)\n",
    "    \"\"\"\n",
    "    \n",
    "    diffs = cdist(x_1, x_2, metric = 'euclidean')\n",
    "    sq_diffs = cdist(x_1, x_2, metric = 'sqeuclidean')\n",
    "    \n",
    "    K_period = np.exp(-2 * np.sin(np.pi * diffs / period)**2 / lengthscale_p)\n",
    "    K_sqe = np.exp(-0.5 * sq_diffs / lengthscale_sqe)\n",
    "    return variance * np.multiply(K_period, K_sqe)\n",
    "\n",
    "locally_periodic(x_1, x_2, 1, 0.5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1b97ff78-eae0-4420-ade4-6cffbcdffb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-26.072041049218555"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LocallyPeriodic(BaseKernel):\n",
    "    def __init__(self, lengthscale_sqe=0.5, variance=1.0, lengthscale_p =0.5, period=1.0):\n",
    "        self.lengthscale_sqe = lengthscale_sqe\n",
    "        self.variance = variance\n",
    "        self.lengthscale_p = lengthscale_p\n",
    "        self.period = period\n",
    "        self.param_dim = 4\n",
    "        super().__init__()\n",
    "    \n",
    "    def make_gram(self, x_1, x_2):\n",
    "        self.gram = locally_periodic(x_1, x_2, self.lengthscale_sqe, self.variance, self.lengthscale_p, self.period)\n",
    "        return self.gram \n",
    "    \n",
    "    def invert_gram(self):\n",
    "        self.inverse_gram = chol_inverse(self.gram)\n",
    "        return self.inverse_gram\n",
    "    \n",
    "    def constrain_params(self, unconstrained_params):\n",
    "        if unconstrained_params.shape[0] != self.param_dim:\n",
    "            raise AssertionError('Parameter array not the same size as kernel parameter dimension')\n",
    "        self.constrained_params = np.exp(unconstrained_params)\n",
    "        return self.constrained_params\n",
    "    \n",
    "    def update_params(self):\n",
    "        self.lengthscale_sqe = self.constrained_params[0]\n",
    "        self.variance = self.constrained_params[1]\n",
    "        self.lengthscale_p = self.constrained_params[2]\n",
    "        self.period = self.constrained_params[3]\n",
    "    \n",
    "    def prior_log_pdf(self, d):\n",
    "        self.prior = gamma.logpdf(self.constrained_params[0], a = 1, scale = np.sqrt(d))\n",
    "        self.prior += gamma.logpdf(self.constrained_params[1], a = 1.2, scale = 1/0.2)\n",
    "        self.prior += gamma.logpdf(self.constrained_params[2], a = 0.00001, scale = 1/0.00001) # uninformative prior\n",
    "        self.prior += gamma.logpdf(self.constrained_params[3], a = 0.00001, scale = 1/0.00001) # uninformative prior\n",
    "        return self.prior\n",
    "\n",
    "kernel = LocallyPeriodic(lengthscale_sqe = 1, variance = 1, lengthscale_p = 0.5, period = 10)\n",
    "kernel.make_gram(x_1, x_1)\n",
    "kernel.constrain_params(np.zeros(4))\n",
    "kernel.prior_log_pdf(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8049a484-c627-4bb3-98ef-44f572757087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.12485862, 3.08382839, 3.33338171, ..., 2.14257458, 3.39988176,\n",
       "        3.0848776 ],\n",
       "       [2.96513369, 3.08075935, 3.22094832, ..., 1.04626758, 3.31858539,\n",
       "        1.64253894],\n",
       "       [1.89121769, 2.7938565 , 3.02204574, ..., 2.02488153, 3.07918173,\n",
       "        2.88243903],\n",
       "       ...,\n",
       "       [1.99913609, 1.94820288, 2.01187183, ..., 0.65604826, 2.07095395,\n",
       "        0.94321709],\n",
       "       [2.96053834, 4.39916247, 4.77465071, ..., 2.96767593, 4.87531942,\n",
       "        4.38618119],\n",
       "       [0.57413216, 1.37396248, 1.5199463 , ..., 1.67340633, 1.52481655,\n",
       "        2.18685359]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear(x_1, x_2, constant_variance=0.5, variance=1.0, offset=1.0):\n",
    "    \"\"\"\n",
    "    A linear kernel is a non-stationary kernel, which when used with a GP, is equivalent to\n",
    "    Bayesian linear regression.\n",
    "    \n",
    "    :param x_1, N x d matrix\n",
    "    :param x_2, M x d matrix\n",
    "\n",
    "    :param constant_variance, float\n",
    "    :param variance, float\n",
    "    :param offset, float\n",
    "\n",
    "    :returns K, N x M matrix, K_{ij} = k(x_i, x_j; constant_variance, variance, offset)\n",
    "    \"\"\"\n",
    "    \n",
    "    return constant_variance + variance*np.dot(x_1 - offset, x_2.T - offset)\n",
    "\n",
    "linear(x_1, x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c2b11a67-20d6-44c1-86e5-e335d3805c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.010841343039882"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Linear(BaseKernel):\n",
    "    def __init__(self, constant_variance=0.5, variance=1.0, offset=1.0):\n",
    "        self.constant_variance = constant_variance\n",
    "        self.variance = variance\n",
    "        self.offset = offset\n",
    "        self.param_dim = 3\n",
    "        super().__init__()\n",
    "    \n",
    "    def make_gram(self, x_1, x_2):\n",
    "        self.gram = linear(x_1, x_2, self.constant_variance, self.variance, self.offset)\n",
    "        return self.gram \n",
    "    \n",
    "    def invert_gram(self):\n",
    "        self.inverse_gram = chol_inverse(self.gram)\n",
    "        return self.inverse_gram\n",
    "    \n",
    "    def constrain_params(self, unconstrained_params):\n",
    "        if unconstrained_params.shape[0] != self.param_dim:\n",
    "            raise AssertionError('Parameter array not the same size as kernel parameter dimension')\n",
    "        self.constrained_params = np.concatenate((np.exp(unconstrained_params[0:2]), unconstrained_params[2].reshape(-1)))\n",
    "        return self.constrained_params\n",
    "    \n",
    "    def update_params(self):\n",
    "        self.constant_variance = self.constrained_params[0]\n",
    "        self.variance = self.constrained_params[1]\n",
    "        self.offset = self.constrained_params[2]\n",
    "    \n",
    "    def prior_log_pdf(self, d):\n",
    "        self.prior = gamma.logpdf(self.constrained_params[1], a = 1.2, scale = 1/0.2)\n",
    "        self.prior += gamma.logpdf(self.constrained_params[1], a = 1.2, scale = 1/0.2)\n",
    "        self.prior += norm.logpdf(self.constrained_params[2]) # Standard Gaussian prior for offset\n",
    "        return self.prior\n",
    "\n",
    "kernel = Linear(constant_variance=0.5, variance=1.0, offset=1.0)\n",
    "kernel.make_gram(x_1, x_1)\n",
    "kernel.constrain_params(np.zeros(3))\n",
    "kernel.prior_log_pdf(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a0cba21b-d50d-4522-92b6-f1465abec6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.60733042, 3.54489056, 4.08152105, ..., 2.47155223, 4.77052975,\n",
       "        2.95145953],\n",
       "       [3.54489056, 4.21036693, 3.36205472, ..., 2.49761874, 3.1517095 ,\n",
       "        1.42409117],\n",
       "       [4.08152105, 3.36205472, 4.23659163, ..., 2.64674966, 4.79607998,\n",
       "        2.57911438],\n",
       "       ...,\n",
       "       [2.47155223, 2.49761874, 2.64674966, ..., 3.09886458, 2.26226533,\n",
       "        1.9155143 ],\n",
       "       [4.77052975, 3.1517095 , 4.79607998, ..., 2.26226533, 7.27866731,\n",
       "        2.58953087],\n",
       "       [2.95145953, 1.42409117, 2.57911438, ..., 1.9155143 , 2.58953087,\n",
       "        3.29646968]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Additive(BaseKernel):\n",
    "    def __init__(self, kernels):\n",
    "        self.kernels = kernels\n",
    "        self.param_dim = sum(k.param_dim for k in self.kernels)\n",
    "        super().__init__()\n",
    "    \n",
    "    def make_gram(self, x_1, x_2):\n",
    "        grams = [k.make_gram(x_1, x_2) for k in self.kernels]\n",
    "        self.gram = sum(grams)\n",
    "        return self.gram\n",
    "        \n",
    "    def invert_gram(self):\n",
    "        self.inverse_gram = chol_inverse(self.gram)\n",
    "        return self.inverse_gram\n",
    "\n",
    "    def constrain_params(self, unconstrained_params):\n",
    "        if unconstrained_params.shape[0] != self.param_dim:\n",
    "            raise AssertionError('Parameter array not the same size as kernel parameter dimension')\n",
    "            \n",
    "        self.constrained_params = np.zeros(0)\n",
    "        dim_count = 0\n",
    "        for k in self.kernels:\n",
    "            self.constrained_params = np.concatenate((self.constrained_params, k.constrain_params(unconstrained_params[dim_count:(dim_count + k.param_dim)])))\n",
    "            dim_count += k.param_dim\n",
    "        return self.constrained_params\n",
    "    \n",
    "    def update_params(self):\n",
    "        for k in self.kernels:\n",
    "            k.update_params()\n",
    "    \n",
    "    def prior_log_pdf(self, d):\n",
    "        self.prior = 0\n",
    "        for k in self.kernels:\n",
    "            self.prior += k.prior_log_pdf(d)\n",
    "        return self.prior\n",
    "\n",
    "k1 = SquaredExponential(lengthscale = 1, variance = 1)\n",
    "k2 = Periodic(lengthscale = 1, variance = 1, period = 1)\n",
    "k3 = Linear(constant_variance = 0.5, variance = 1, offset = 1)\n",
    "\n",
    "kadd = Additive([k1, k2, k3])\n",
    "\n",
    "kadd.make_gram(x_1, x_1)\n",
    "\n",
    "kadd.constrain_params(np.array([1, 2, 3, 4, 5, 6, 7, 8]))\n",
    "kadd.update_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa138d93-f9ca-4669-a03f-a3c6181b1f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2.71828183,    7.3890561 ,   20.08553692,   54.59815003,\n",
       "        148.4131591 ,  403.42879349, 1096.63315843,    8.        ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Multiplicative(BaseKernel):\n",
    "    def __init__(self, kernels):\n",
    "        self.kernels = kernels\n",
    "        self.param_dim = sum(k.param_dim for k in self.kernels)\n",
    "        super().__init__()\n",
    "    \n",
    "    def make_gram(self, x_1, x_2):\n",
    "        grams = [k.make_gram(x_1, x_2) for k in self.kernels]\n",
    "        self.gram = reduce(np.multiply, grams)\n",
    "        return self.gram\n",
    "        \n",
    "    def invert_gram(self):\n",
    "        self.inverse_gram = chol_inverse(self.gram)\n",
    "        return self.inverse_gram\n",
    "    \n",
    "    def constrain_params(self, unconstrained_params):\n",
    "        if unconstrained_params.shape[0] != self.param_dim:\n",
    "            raise AssertionError('Parameter array not the same size as kernel parameter dimension')\n",
    "            \n",
    "        self.constrained_params = np.zeros(0)\n",
    "        dim_count = 0\n",
    "        for k in self.kernels:\n",
    "            self.constrained_params = np.concatenate((self.constrained_params, k.constrain_params(unconstrained_params[dim_count:(dim_count + k.param_dim)])))\n",
    "            dim_count += k.param_dim\n",
    "        return self.constrained_params\n",
    "    \n",
    "    def update_params(self):\n",
    "        for k in self.kernels:\n",
    "            k.update_params()\n",
    "    \n",
    "    def prior_log_pdf(self, d):\n",
    "        self.prior = 0\n",
    "        for k in self.kernels:\n",
    "            self.prior += k.prior_log_pdf(d)\n",
    "        return self.prior\n",
    "    \n",
    "k1 = SquaredExponential(lengthscale = 1, variance = 1)\n",
    "k2 = Periodic(lengthscale = 1, variance = 1, period = 10)\n",
    "k3 = Linear(constant_variance = 0.5, variance = 1, offset = 1)\n",
    "\n",
    "kmul = Multiplicative([k1, k2, k3])\n",
    "\n",
    "kmul.make_gram(x_1, x_1)\n",
    "kmul.constrain_params(np.array([1, 2, 3, 4, 5, 6, 7, 8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87960ae-366a-4f64-bf6d-77ed459eed93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add(x_1, x_2, kernels):\n",
    "    \"\"\"\n",
    "    Add together an arbitrary number of kernels.\n",
    "    \n",
    "    :param x_1, N x d matrix\n",
    "    :param x_2, M x d matrix\n",
    "    \n",
    "    :param kernels, tuple, tuple consisting of kernel functions, and corresponding parameter dictionaries\n",
    "    \n",
    "    :returns K, N x M matrix, sum of kernel matrices \n",
    "    \"\"\"\n",
    "    \n",
    "    return sum([\n",
    "        kernel(x_1, x_2, **kernel_kwargs)\n",
    "        for kernel, kernel_kwargs in kernels\n",
    "    ])\n",
    "\n",
    "kernels = (\n",
    "    (locally_periodic, {'lengthscale':0.5, 'variance':1.0, 'period':1.0}),\n",
    "    (periodic, {'lengthscale':0.5, 'variance':1.0, 'period':0.1}),\n",
    ")\n",
    "\n",
    "add(x_1, x_2, kernels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b542d7f8-d79b-4837-bdc2-9de745e57d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 25)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiply(x_1, x_2, kernels):\n",
    "    \"\"\"\n",
    "    Multiply together an arbitrary number of kernels.\n",
    "    \n",
    "    :param x_1, N x d matrix\n",
    "    :param x_2, M x d matrix\n",
    "    \n",
    "    :param kernels, tuple, kernel functions and corresponding parameter dictionaries\n",
    "    \n",
    "    :returns K, N x M matrix, sum of kernel matrices \n",
    "    \"\"\"\n",
    "    \n",
    "    grams = [\n",
    "    kernel(x_1, x_2, **kernel_kwargs) \n",
    "    for kernel, kernel_kwargs in kernels\n",
    "    ]\n",
    "    \n",
    "    return reduce(np.multiply, grams)\n",
    "\n",
    "kernels = (\n",
    "    (linear, {'constant_variance':0, 'variance':1.0, 'offset':0}),\n",
    "    (periodic, {'lengthscale':0.5, 'variance':1.0, 'period':0.1}),\n",
    "    (locally_periodic, {'lengthscale':0.5, 'variance':1.0, 'period':10})\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "multiply(x_1, x_2, kernels).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
