{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7cf671-9b20-4264-b766-aa93743d018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scipy.stats import gamma, multivariate_normal\n",
    "\n",
    "from gproc.elliptic import ess_samples_probit\n",
    "from gproc.generative import sample_at_x\n",
    "from gproc.kernels import *\n",
    "from gproc.laplace import laplace_approximation_probit, chol_inverse\n",
    "from gproc.approx_marginal_is import importance_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29292d-a04a-4d1b-88f9-4bde77ae478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "JITTER = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190a356-5976-4567-b889-a2e4437c496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500 # Data size\n",
    "D = 1 # Data dimension\n",
    "\n",
    "x = np.random.normal(0, 1, N * D).reshape(-1, D) # Reshape to N x D matrix\n",
    "y, prob_y, f = sample_at_x(x, kernel_fcn = squared_exponential, kernel_params = {'lengthscale': 1, 'variance': 3})\n",
    "\n",
    "th_0 = np.array([1, 1])\n",
    "gram = squared_exponential(x, x, lengthscale = th_0[0], variance = th_0[1])\n",
    "inverse_gram = chol_inverse(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ebb7f-8b88-45bd-9aa3-a82798395d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get approximation to latent function posterior\n",
    "laplace_mean, df_ll, laplace_cov, objective_history, converged = laplace_approximation_probit(y, inverse_gram)\n",
    "\n",
    "print(f'Converged: {converged}')\n",
    "\n",
    "marg_0 = importance_sampler(y, x, laplace_mean, laplace_cov, 100)\n",
    "marg_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8286ec-7cee-4a96-82df-f75424e87e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mh_step(y, x, th_old, marg_old, cov, N_imp = 100):\n",
    "    \"\"\"\n",
    "    Performs one transition of the Pseudo-Marginal Metropolis Hastings algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: N dimensional numpy vector\n",
    "        responses\n",
    "    \n",
    "    x: N x D dimensional numpy array\n",
    "        covariates\n",
    "\n",
    "    th_old: numpy vector\n",
    "        contains old kernel parameters\n",
    "\n",
    "    marg_old: float\n",
    "        contains old approximation of the marginal\n",
    "        \n",
    "    cov: numpy array\n",
    "        covariance matrix for use in the proposal distribution\n",
    "        \n",
    "    N_imp: float\n",
    "        Number of importance samples to use in marginal approximation\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    th_new: numpy vector\n",
    "        new sample kernel parameters\n",
    "    \n",
    "    marg_new: float\n",
    "        new marginal approximation\n",
    "    \n",
    "    move: boolean\n",
    "        flag indicating whether or not we moved\n",
    "    \"\"\"\n",
    "        \n",
    "    # Draw kernel parameters from proposal distribution\n",
    "    th_new = np.random.multivariate_normal(th_old, cov, 1)[0]\n",
    "\n",
    "    # Reparameterise old and new kernel parameters\n",
    "    l_old = np.exp(th_old[0])\n",
    "    var_old = np.exp(th_old[1]) \n",
    "    \n",
    "    l_new = np.exp(th_new[0])\n",
    "    var_new = np.exp(th_new[1]) \n",
    "                             \n",
    "    # Create new kernel matrix, and make new approximation\n",
    "    gram = squared_exponential(x, x, lengthscale = l_new, variance = var_new)\n",
    "    inverse_gram = chol_inverse(gram)\n",
    "    laplace_mean, df_ll, laplace_cov, objective_history, converged = laplace_approximation_probit(y, inverse_gram)\n",
    "    \n",
    "    # Compute new marginal approximation\n",
    "    marg_new = importance_sampler(y, x, laplace_mean, laplace_cov, N_imp)\n",
    "    \n",
    "    # Compute MH log ratio\n",
    "    # Dimension for Gamma prior hyperameters in MH ratio\n",
    "    d = x.shape[1]\n",
    "    numer = marg_new +  gamma.logpdf(l_new, a = 1, scale = np.sqrt(d)) + gamma.logpdf(var_new, a = 1.2, scale = 1/0.2) + multivariate_normal.logpdf(th_old, mean = th_new)\n",
    "    denom = marg_old +  gamma.logpdf(l_old, a = 1, scale = np.sqrt(d)) + gamma.logpdf(var_old, a = 1.2, scale = 1/0.2) + multivariate_normal.logpdf(th_new, mean = th_old)\n",
    "    logratio = numer - denom\n",
    "    \n",
    "    # Check if we should move\n",
    "    move = False\n",
    "    u = np.random.uniform(0, 1, 1)\n",
    "    if logratio > np.log(u):\n",
    "        move = True\n",
    "        return th_new, marg_new, move\n",
    "    else:\n",
    "        return th_old, marg_old, move\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb9cfa-d1c3-4256-8deb-8c45d2ecb28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mh(iters, y, x, th_0, marg_0, cov, N_imp = 100, verbose = False):\n",
    "    \"\"\"\n",
    "    Function that generates samples from the posterior distribution over\n",
    "    kernel parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    iters: float\n",
    "        number of iterations of the Metropolis Hastings algorithm\n",
    "        \n",
    "    y: N dimensional numpy vector\n",
    "        responses\n",
    "    \n",
    "    x: N x D dimensional numpy array\n",
    "        covariates\n",
    "\n",
    "    th_0: numpy vector\n",
    "        initial kernel parameters\n",
    "\n",
    "    marg_0: float\n",
    "        initial approximation of the marginal\n",
    "        \n",
    "    cov: numpy array\n",
    "        covariance matrix for use in the proposal distribution\n",
    "        \n",
    "    N_imp: float\n",
    "        number of importance samples to use in marginal approximation\n",
    "    \n",
    "    verbose: boolean\n",
    "        flag to produce loading bar\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    th_arr: numpy array\n",
    "        contains the chains move history\n",
    "    \n",
    "    marg_arr: numpy array\n",
    "        contains the history of marginal approximations\n",
    "    \n",
    "    acc_rate: float\n",
    "        acceptance rate of moves\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create array to hold samples and move history\n",
    "    th_arr = np.zeros((iters + 1, th_0.shape[0]))\n",
    "    marg_arr = np.zeros(iters + 1)\n",
    "    move_arr = np.zeros(iters)\n",
    "    \n",
    "    # Add initialisation\n",
    "    th_arr[0, :] = th_0\n",
    "    marg_arr[0] = marg_0\n",
    "    \n",
    "    for i in tqdm(range(iters), disable=not(verbose)):\n",
    "        th_arr[i + 1, :], marg_arr[i + 1], move_arr[i] = mh_step(y, x, th_arr[i, :], marg_arr[i], cov = cov, N_imp = N_imp)\n",
    "    \n",
    "    acc_rate = move_arr.mean()\n",
    "    return th_arr, marg_arr, acc_rate\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a778b6b4-56f7-44fd-9cd6-d6a5e32290e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_arr, marg_arr, acc_rate = mh(1000, y, x, th_0, marg_0, cov = 0.5*np.eye(th_0.shape[0]), N_imp = 100, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb44dd61-39f5-48fa-befa-08f383b3d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_rate*100)\n",
    "plt.plot(np.exp(th_arr[:, 0]))\n",
    "plt.plot(np.exp(th_arr[:, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d61cd47-166d-4cfe-9d7e-422b6d25d2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
